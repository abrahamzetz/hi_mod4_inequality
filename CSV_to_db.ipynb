{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSV to db.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrahamzetz/hyperisland/blob/module4_data_analysis/CSV_to_db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "034-PBuUdbIk"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpqLwbYaX4be"
      },
      "source": [
        "This is the same setup like what Andrea showed us on the Bootcamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPSFYAOW5p3L"
      },
      "source": [
        "# Load some libraries we need\n",
        "import pandas as pd\n",
        "%load_ext google.colab.data_table\n",
        "import sqlite3 as sql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVfihKMA5ewG"
      },
      "source": [
        "# Mount Goole Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "% cd gdrive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezXRL82vS0s7"
      },
      "source": [
        "In this case I will use hyper_jobs.db that Andrea shared with us.\n",
        "\n",
        "What you need to do is go to your Google Drive, make a copy of the hyper_jobs.db, and rename the copy to anything of your choice.\n",
        "\n",
        "For the sake of this exercise I will name it your.db"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6btNY35g5v-S"
      },
      "source": [
        "# We connect to the database\n",
        "# Be careful to the path, better to copy/paste it\n",
        "db_conn = sql.connect(\"/content/gdrive/MyDrive/your.db\")\n",
        "#You can change your.db to the name of the database that you have just copied"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IICI56m0rWx"
      },
      "source": [
        "#Importing .csv to .db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjlKBck_Ty8K"
      },
      "source": [
        "Now we want to import the .csv file into a table in our database.\n",
        "\n",
        "For this method to work, you have to upload your .csv files to your Google Drive.\n",
        "\n",
        "I created a folder called data to make it clean, but you can do what works best for you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6aYF3e52d1P"
      },
      "source": [
        "#import csv to DataFrame\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/data/da23crew.csv\"\n",
        "#In this example, I uploaded da23crew.csv file into the data folder I just created.\n",
        "#You can change the name to your .csv file, and make sure the path is correct.\n",
        "#If you didn't create a folder called data, then remove the /data path\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6u-5fvc4Un_"
      },
      "source": [
        "#check if data is correctly stored in DataFrame, you should see your table displayed properly\n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYsZwPiuU2b4"
      },
      "source": [
        "Now the table has been stored to a DataFrame, which in my understanding is a temporary storage (correct me if I'm wrong).\n",
        "\n",
        "To put it permanently to a table, do the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwirR7-68hIL"
      },
      "source": [
        "#convert the data from DataFrame to SQL table\n",
        "\n",
        "df.to_sql\n",
        "#You can change table_name to whatever you want to name your table as.\n",
        "#If there is already a table with the same name, the content will be replaced by the new one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLBQm7_iVebz"
      },
      "source": [
        "You can see the tables you have in the .db file by running the following.\n",
        "\n",
        "(You'll notice irrelevant tables like employers, jobs, cities, etc. Don't worry about it now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBWZE4DYVccL"
      },
      "source": [
        "#show all tables\n",
        "\n",
        "pd.read_sql(\n",
        "  \"\"\"\n",
        "        select *\n",
        "        from sqlite_master\n",
        "        \n",
        "  \"\"\", db_conn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2ej8hgVuyg"
      },
      "source": [
        "You can repeat the steps in the importing .csv to .db section until you have added all the .csv files you need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIla333VV01"
      },
      "source": [
        "#Deleting irrelevant tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwho7lgUV7LA"
      },
      "source": [
        "Since we're copy-pasting hyper_jobs.db, the old tables like employers, jobs, cities, etc are still included in your.db file.\n",
        "\n",
        "Follow the steps below to delete them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSjZj_UdtDck"
      },
      "source": [
        "#Deleting Table\n",
        "\n",
        "#Creating a cursor object using the cursor() method\n",
        "cursor = db_conn.cursor()\n",
        "\n",
        "#Doping EMPLOYEE table if already exists\n",
        "cursor.execute(\"DROP TABLE employers\")\n",
        "#You can change employers to the name of the table you want to delete\n",
        "\n",
        "#After successful deletion, you should get the following text\n",
        "print(\"Table dropped... \")\n",
        "\n",
        "#Commit your changes in the database\n",
        "db_conn.commit()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjk8G_iQbsOk"
      },
      "source": [
        "You can see the tables you have in the .db file by running the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqJWcN7hbr8u"
      },
      "source": [
        "#show all tables\n",
        "\n",
        "pd.read_sql(\n",
        "  \"\"\"\n",
        "        select *\n",
        "        from sqlite_master\n",
        "        \n",
        "  \"\"\", db_conn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS8M05xOXNNc"
      },
      "source": [
        "Repeat the steps above and change the name of the table until all the irrelevant tables are deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RnVgISFXZjx"
      },
      "source": [
        "#Goodbye"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuXDFr85YPIi"
      },
      "source": [
        "Now you'll be able to query with SQL using the template Andrea shared with us on Bootcamp like below\n",
        "\n",
        "```\n",
        "pd.read_sql(\n",
        "  \"\"\"\n",
        "        SQL HERE\n",
        "        SQL HERE\n",
        "        SQL HERE\n",
        "\n",
        "  \"\"\", db_conn)\n",
        "```\n",
        "\n",
        "\n",
        "    \n",
        "So that's it!\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc9mMoO4XeTo"
      },
      "source": [
        "Disclaimer:\n",
        "\n",
        "I'm not at all a python expert. In fact, I haven't learned properly how to use python. \n",
        "\n",
        "This is just something I found online and was able to put together and tweak for me to use. Hope this helps!\n",
        "\n",
        "Peace out,\n",
        "\n",
        "Abraham"
      ]
    }
  ]
}